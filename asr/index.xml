<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>基于kaldi的语音识别 on Codist</title>
    <link>https://blog.codist.me/asr/</link>
    <description>Recent content in 基于kaldi的语音识别 on Codist</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://blog.codist.me/asr/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>安装kaldi</title>
      <link>https://blog.codist.me/asr/kaldi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.codist.me/asr/kaldi/</guid>
      <description>1.环境 操作系统建议使用ubuntu，因为源里已经有编译好的一些依赖库，如ATLAS，安装不会遇到太多问题。
需要安装有git和make以及gcc等编译工具链
2.从源码安装 1.下载源码：
git clone https://github.com/kaldi-asr/kaldi.git  安装文档在kaldi/tools/INSTALL，很短，建议阅读一下
2.检查依赖和安装：
#检查依赖，如有问题参照仔细修改 ./extras/check_dependencies.sh #自动下载安装依赖 make -j 8  这会安装ATLAS headers, OpenFst, SCTK 和 sph2pipe
3.由于ATLAS安装复杂，使用OpenBLAS：
./extras/install_openblas.sh  4.根据安装文档下载编译依赖(这里使用OpenBLAS)，需要硬盘上有20G的空闲空间：
./configure --openblas-root=../tools/OpenBLAS/install make depend -j 8 make -j 8  这样就已经编译好训练需要的工具，之后进行在线解码和处理一些数据集需要额外安装一些工具</description>
    </item>
    
    <item>
      <title>使用thchs30数据集</title>
      <link>https://blog.codist.me/asr/thchs30/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.codist.me/asr/thchs30/</guid>
      <description>1.下载数据集 Kaldi中文语音识别公共数据集有：
 1.aishell：AI SHELL公司开源178小时中文语音语料及基本训练脚本，见kaldi-master/egs/aishell
 2.gale_mandarin：中文新闻广播数据集(LDC2013S08, LDC2013S08）
 3.hkust：中文电话数据集(LDC2005S15, LDC2005T32)
 4.thchs30：清华大学30小时的数据集，可以在http://www.openslr.org/18/ 下载
  这里采用thchs30，从http://www.openslr.org/18/ 或者参照它的README下载三个压缩包：
 data_thchs30.tgz 6.4G Mirrors: China
 test-noise.tgz 1.9G Mirrors: China
 resource.tgz 24M Mirrors: China
  在egs/thchs30/s5下新建文件夹thchs30-openslr，把三个文件解压在该文件夹下
这个数据集包含以下内容：
   数据集 音频时长(h) 句子数 词数     train(训练) 25 10000 198252   dev(开发) 2:14 893 17743   test(测试) 6:15 2495 49085    还有训练好的语言模型word.3gram.lm和phone.3gram.lm以及相应的词典lexicon.txt。
其中dev的作用是在某些步骤与train进行交叉验证的，如local/nnet/run_dnn.sh同时用到exp/tri4b_ali和exp/tri4b_ali_cv。训练和测试的目标数据也分为两类：word（词）和phone（音素）。</description>
    </item>
    
  </channel>
</rss>